{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suicide Rate Prediction Regression Model\n",
    "\n",
    "The purpose of this notebook is to create a regression model to predict the suicide rate of a city in a certain year. \n",
    "\n",
    "The features used for this model are the disease rates from the previous year for that city, as well as the state where it is located and the suicide rate from the previous year.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# DataPrep\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "# Tuning\n",
    "from skopt import gp_minimize\n",
    "# Feature Selection\n",
    "from sklearn.feature_selection import RFE,SelectFromModel\n",
    "# Models\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "# Evaluation\n",
    "from sklearn import metrics\n",
    "\n",
    "# Plotting\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import geoplot\n",
    "import mapclassify\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "import glob\n",
    "import shap\n",
    "root = \"../../\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_uf_cod = {11: 'RO', 12: 'AC', 13: 'AM', 14: 'RR', 15: 'PA', 16: 'AP', 17: 'TO',\n",
    "21: 'MA', 22: 'PI', 23: 'CE', 24: 'RN', 25: 'PB', 26: 'PE', 27: 'AL', 28: 'SE',\n",
    "29: 'BA', 31: 'MG', 32: 'ES', 33: 'RJ', 35: 'SP', 41: 'PR', 42: 'SC', 43: 'RS',\n",
    "50: 'MS', 51: 'MT', 52: 'GO', 53: 'DF'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataPrep\n",
    "*You can skip this and load the csv directly after this section*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataPrep (models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting a list of all diseases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313  diseases\n"
     ]
    }
   ],
   "source": [
    "disease = \"\"\n",
    "path = root + \"CSV/TabNet/Internacoes_Rate/\"\n",
    "all_files = glob.glob(path + \"*.csv\")\n",
    "suicide = pd.read_csv(root +'CSV/Suicide/suicide_rates_08_18.csv', index_col=0)\n",
    "\n",
    "years = [str(x).zfill(2) for x in range(8,19)]\n",
    "columns = [\"RATE_\" + year for year in years]\n",
    "columns.append(\"MUNCOD\")\n",
    "\n",
    "disease_list = []\n",
    "\n",
    "for file in all_files:\n",
    "    file_name = file.split(\"\\\\\")[-1]\n",
    "    disease = file_name.split(\".csv\")[0]\n",
    "    disease_df = pd.read_csv(file, sep=',', index_col=0)\n",
    "    if(set(disease_df.columns) == set(columns)):\n",
    "        disease_list.append(disease)\n",
    "print(len(disease_list), \" diseases\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating dataframe by using only rows with **at least 80% values that are not NaN** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ÚLCERA_GÁSTRICA_E_DUODENAL</th>\n",
       "      <th>MUNCOD</th>\n",
       "      <th>VEIAS_VARICOSAS_DAS_EXTREMIDADES_INFERIORES</th>\n",
       "      <th>VARICELA_E_HERPES_ZOSTER</th>\n",
       "      <th>UROLITÍASE</th>\n",
       "      <th>TÉTANO_NEONATAL</th>\n",
       "      <th>TUBERC_INTEST_PERITÔNIO_GLÂNGL_MESENTÉRICOS</th>\n",
       "      <th>TUBERCULOSE_ÓSSEA_E_DAS_ARTICULAÇÕES</th>\n",
       "      <th>TUBERCULOSE_PULMONAR</th>\n",
       "      <th>TUBERCULOSE_MILIAR</th>\n",
       "      <th>...</th>\n",
       "      <th>ANCILOSTOMÍASE</th>\n",
       "      <th>AMEBÍASE</th>\n",
       "      <th>ALGUNS_TRANSTORNOS_ENVOLVENDO_MECANISMO_IMUNITÁRIO</th>\n",
       "      <th>AFECÇ_HEMORRÁG_E_OUTR_DOENÇ_SANG_E_ÓRG_HEMATOPOÉT</th>\n",
       "      <th>ACID_VASCULAR_CEREBR_NÃO_ESPEC_HEMORRÁG_OU_ISQUÊM</th>\n",
       "      <th>ACID_VASCULAR_CEREBR_ISQUÊM_TRANSIT_E_SÍNDR_CORREL</th>\n",
       "      <th>ABORTO_POR_RAZÕES_MÉDICAS</th>\n",
       "      <th>ABORTO_ESPONTÂNEO</th>\n",
       "      <th>PREVIOUS</th>\n",
       "      <th>RATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.481914</td>\n",
       "      <td>110001</td>\n",
       "      <td>40.688449</td>\n",
       "      <td>0.0</td>\n",
       "      <td>142.409570</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.757293</td>\n",
       "      <td>40.688449</td>\n",
       "      <td>32.550759</td>\n",
       "      <td>NaN</td>\n",
       "      <td>126.134191</td>\n",
       "      <td>20.344224</td>\n",
       "      <td>8.212203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.458389</td>\n",
       "      <td>110002</td>\n",
       "      <td>54.385737</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.369882</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.182299</td>\n",
       "      <td>39.015855</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.182299</td>\n",
       "      <td>9.458389</td>\n",
       "      <td>2.338060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.110972</td>\n",
       "      <td>110004</td>\n",
       "      <td>21.721631</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.887150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.833229</td>\n",
       "      <td>106.052669</td>\n",
       "      <td>3.833229</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.555486</td>\n",
       "      <td>5.110972</td>\n",
       "      <td>7.626311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>110009</td>\n",
       "      <td>48.921969</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.460985</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.494426</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.472132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.922331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.466639</td>\n",
       "      <td>110010</td>\n",
       "      <td>9.866555</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.333194</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.466639</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.466639</td>\n",
       "      <td>36.999581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>197.331097</td>\n",
       "      <td>2.466639</td>\n",
       "      <td>7.359796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 316 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ÚLCERA_GÁSTRICA_E_DUODENAL  MUNCOD  \\\n",
       "0                   28.481914  110001   \n",
       "1                    9.458389  110002   \n",
       "3                    5.110972  110004   \n",
       "8                    0.000000  110009   \n",
       "9                    2.466639  110010   \n",
       "\n",
       "   VEIAS_VARICOSAS_DAS_EXTREMIDADES_INFERIORES  VARICELA_E_HERPES_ZOSTER  \\\n",
       "0                                    40.688449                       0.0   \n",
       "1                                    54.385737                       0.0   \n",
       "3                                    21.721631                       0.0   \n",
       "8                                    48.921969                       0.0   \n",
       "9                                     9.866555                       0.0   \n",
       "\n",
       "   UROLITÍASE  TÉTANO_NEONATAL  TUBERC_INTEST_PERITÔNIO_GLÂNGL_MESENTÉRICOS  \\\n",
       "0  142.409570              NaN                                          NaN   \n",
       "1   15.369882              NaN                                          0.0   \n",
       "3   63.887150              NaN                                          NaN   \n",
       "8   24.460985              NaN                                          NaN   \n",
       "9   12.333194              NaN                                          0.0   \n",
       "\n",
       "   TUBERCULOSE_ÓSSEA_E_DAS_ARTICULAÇÕES  TUBERCULOSE_PULMONAR  \\\n",
       "0                                   NaN                   0.0   \n",
       "1                                   NaN                   0.0   \n",
       "3                                   NaN                   0.0   \n",
       "8                                   NaN                   0.0   \n",
       "9                                   0.0                   0.0   \n",
       "\n",
       "   TUBERCULOSE_MILIAR  ...  ANCILOSTOMÍASE  AMEBÍASE  \\\n",
       "0                 NaN  ...             NaN  0.000000   \n",
       "1                 0.0  ...             NaN  0.000000   \n",
       "3                 0.0  ...             NaN       NaN   \n",
       "8                 NaN  ...             NaN  0.000000   \n",
       "9                 0.0  ...             0.0  2.466639   \n",
       "\n",
       "   ALGUNS_TRANSTORNOS_ENVOLVENDO_MECANISMO_IMUNITÁRIO  \\\n",
       "0                                                NaN    \n",
       "1                                                0.0    \n",
       "3                                                0.0    \n",
       "8                                                NaN    \n",
       "9                                                NaN    \n",
       "\n",
       "   AFECÇ_HEMORRÁG_E_OUTR_DOENÇ_SANG_E_ÓRG_HEMATOPOÉT  \\\n",
       "0                                          44.757293   \n",
       "1                                           1.182299   \n",
       "3                                           3.833229   \n",
       "8                                           3.494426   \n",
       "9                                           2.466639   \n",
       "\n",
       "   ACID_VASCULAR_CEREBR_NÃO_ESPEC_HEMORRÁG_OU_ISQUÊM  \\\n",
       "0                                          40.688449   \n",
       "1                                          39.015855   \n",
       "3                                         106.052669   \n",
       "8                                           0.000000   \n",
       "9                                          36.999581   \n",
       "\n",
       "   ACID_VASCULAR_CEREBR_ISQUÊM_TRANSIT_E_SÍNDR_CORREL  \\\n",
       "0                                          32.550759    \n",
       "1                                           0.000000    \n",
       "3                                           3.833229    \n",
       "8                                          17.472132    \n",
       "9                                           0.000000    \n",
       "\n",
       "   ABORTO_POR_RAZÕES_MÉDICAS  ABORTO_ESPONTÂNEO   PREVIOUS      RATE  \n",
       "0                        NaN         126.134191  20.344224  8.212203  \n",
       "1                        0.0           1.182299   9.458389  2.338060  \n",
       "3                        0.0           2.555486   5.110972  7.626311  \n",
       "8                        0.0           0.000000   0.000000  6.922331  \n",
       "9                        0.0         197.331097   2.466639  7.359796  \n",
       "\n",
       "[5 rows x 316 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_df = pd.DataFrame()\n",
    "percentage_valid_values = 0.8\n",
    "for i in range(len(years)-1):\n",
    "    col_year_suicide = \"RATE_\" + years[i+1]\n",
    "    col_year_prev = \"RATE_\" + years[i]\n",
    "    year_df = suicide[[col_year_prev, col_year_suicide, \"MUNCOD\"]]\n",
    "    year_df = year_df.rename(columns={col_year_suicide: \"RATE\"})\n",
    "    year_df = year_df.rename(columns={col_year_prev: \"PREVIOUS\"})\n",
    "    for disease in disease_list:\n",
    "        col_year_disease = \"RATE_\" + years[i]\n",
    "        disease_df = pd.read_csv(path + disease + \".csv\", sep=',', index_col=0)\n",
    "        disease_df = disease_df[[col_year_disease, \"MUNCOD\"]]\n",
    "        disease_df = disease_df.rename(columns={col_year_disease: disease})\n",
    "\n",
    "        year_df = pd.merge(disease_df, year_df, left_on=\"MUNCOD\", right_on=\"MUNCOD\", how='right')\n",
    "    N = int(year_df.shape[1]*percentage_valid_values)  \n",
    "    year_df = year_df.dropna(thresh=N)\n",
    "    initial_df = pd.concat([initial_df, year_df])\n",
    "\n",
    "initial_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filling NaN values with zero and getting state code from MUNCOD column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ÚLCERA_GÁSTRICA_E_DUODENAL</th>\n",
       "      <th>VEIAS_VARICOSAS_DAS_EXTREMIDADES_INFERIORES</th>\n",
       "      <th>VARICELA_E_HERPES_ZOSTER</th>\n",
       "      <th>UROLITÍASE</th>\n",
       "      <th>TÉTANO_NEONATAL</th>\n",
       "      <th>TUBERC_INTEST_PERITÔNIO_GLÂNGL_MESENTÉRICOS</th>\n",
       "      <th>TUBERCULOSE_ÓSSEA_E_DAS_ARTICULAÇÕES</th>\n",
       "      <th>TUBERCULOSE_PULMONAR</th>\n",
       "      <th>TUBERCULOSE_MILIAR</th>\n",
       "      <th>TUBERCULOSE_DO_SISTEMA_NERVOSO</th>\n",
       "      <th>...</th>\n",
       "      <th>PR</th>\n",
       "      <th>RJ</th>\n",
       "      <th>RN</th>\n",
       "      <th>RO</th>\n",
       "      <th>RR</th>\n",
       "      <th>RS</th>\n",
       "      <th>SC</th>\n",
       "      <th>SE</th>\n",
       "      <th>SP</th>\n",
       "      <th>TO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.481914</td>\n",
       "      <td>40.688449</td>\n",
       "      <td>0.0</td>\n",
       "      <td>142.409570</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.458389</td>\n",
       "      <td>54.385737</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.369882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.110972</td>\n",
       "      <td>21.721631</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.887150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>48.921969</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.460985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.466639</td>\n",
       "      <td>9.866555</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.333194</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 342 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ÚLCERA_GÁSTRICA_E_DUODENAL  VEIAS_VARICOSAS_DAS_EXTREMIDADES_INFERIORES  \\\n",
       "0                   28.481914                                    40.688449   \n",
       "1                    9.458389                                    54.385737   \n",
       "3                    5.110972                                    21.721631   \n",
       "8                    0.000000                                    48.921969   \n",
       "9                    2.466639                                     9.866555   \n",
       "\n",
       "   VARICELA_E_HERPES_ZOSTER  UROLITÍASE  TÉTANO_NEONATAL  \\\n",
       "0                       0.0  142.409570              0.0   \n",
       "1                       0.0   15.369882              0.0   \n",
       "3                       0.0   63.887150              0.0   \n",
       "8                       0.0   24.460985              0.0   \n",
       "9                       0.0   12.333194              0.0   \n",
       "\n",
       "   TUBERC_INTEST_PERITÔNIO_GLÂNGL_MESENTÉRICOS  \\\n",
       "0                                          0.0   \n",
       "1                                          0.0   \n",
       "3                                          0.0   \n",
       "8                                          0.0   \n",
       "9                                          0.0   \n",
       "\n",
       "   TUBERCULOSE_ÓSSEA_E_DAS_ARTICULAÇÕES  TUBERCULOSE_PULMONAR  \\\n",
       "0                                   0.0                   0.0   \n",
       "1                                   0.0                   0.0   \n",
       "3                                   0.0                   0.0   \n",
       "8                                   0.0                   0.0   \n",
       "9                                   0.0                   0.0   \n",
       "\n",
       "   TUBERCULOSE_MILIAR  TUBERCULOSE_DO_SISTEMA_NERVOSO  ...  PR  RJ  RN  RO  \\\n",
       "0                 0.0                             0.0  ...   0   0   0   1   \n",
       "1                 0.0                             0.0  ...   0   0   0   1   \n",
       "3                 0.0                             0.0  ...   0   0   0   1   \n",
       "8                 0.0                             0.0  ...   0   0   0   1   \n",
       "9                 0.0                             0.0  ...   0   0   0   1   \n",
       "\n",
       "   RR  RS  SC  SE  SP  TO  \n",
       "0   0   0   0   0   0   0  \n",
       "1   0   0   0   0   0   0  \n",
       "3   0   0   0   0   0   0  \n",
       "8   0   0   0   0   0   0  \n",
       "9   0   0   0   0   0   0  \n",
       "\n",
       "[5 rows x 342 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = initial_df.copy()\n",
    "\n",
    "# Fill NaN values with 0\n",
    "df = df.fillna(0)\n",
    "\n",
    "# Get MUNCOD from UF\n",
    "df['UF'] = df['MUNCOD'] / 10000\n",
    "df['UF'] = df['UF'].astype(int)\n",
    "df['UF'].replace(dict_uf_cod, inplace=True)\n",
    "dummy = pd.get_dummies(df['UF'])\n",
    "df = pd.concat([df, dummy], axis=1)\n",
    "df = df.drop(['MUNCOD', 'UF'], axis=1)\n",
    "\n",
    "# Removing outliers\n",
    "df = df[(np.abs(stats.zscore(df[\"RATE\"])) < 3)] \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"df_regression.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataPrep (2018 predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting training data (2008-2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ÚLCERA_GÁSTRICA_E_DUODENAL</th>\n",
       "      <th>MUNCOD</th>\n",
       "      <th>VEIAS_VARICOSAS_DAS_EXTREMIDADES_INFERIORES</th>\n",
       "      <th>VARICELA_E_HERPES_ZOSTER</th>\n",
       "      <th>UROLITÍASE</th>\n",
       "      <th>TÉTANO_NEONATAL</th>\n",
       "      <th>TUBERC_INTEST_PERITÔNIO_GLÂNGL_MESENTÉRICOS</th>\n",
       "      <th>TUBERCULOSE_ÓSSEA_E_DAS_ARTICULAÇÕES</th>\n",
       "      <th>TUBERCULOSE_PULMONAR</th>\n",
       "      <th>TUBERCULOSE_MILIAR</th>\n",
       "      <th>...</th>\n",
       "      <th>ANCILOSTOMÍASE</th>\n",
       "      <th>AMEBÍASE</th>\n",
       "      <th>ALGUNS_TRANSTORNOS_ENVOLVENDO_MECANISMO_IMUNITÁRIO</th>\n",
       "      <th>AFECÇ_HEMORRÁG_E_OUTR_DOENÇ_SANG_E_ÓRG_HEMATOPOÉT</th>\n",
       "      <th>ACID_VASCULAR_CEREBR_NÃO_ESPEC_HEMORRÁG_OU_ISQUÊM</th>\n",
       "      <th>ACID_VASCULAR_CEREBR_ISQUÊM_TRANSIT_E_SÍNDR_CORREL</th>\n",
       "      <th>ABORTO_POR_RAZÕES_MÉDICAS</th>\n",
       "      <th>ABORTO_ESPONTÂNEO</th>\n",
       "      <th>PREVIOUS</th>\n",
       "      <th>RATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.481914</td>\n",
       "      <td>110001</td>\n",
       "      <td>40.688449</td>\n",
       "      <td>0.0</td>\n",
       "      <td>142.409570</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.757293</td>\n",
       "      <td>40.688449</td>\n",
       "      <td>32.550759</td>\n",
       "      <td>NaN</td>\n",
       "      <td>126.134191</td>\n",
       "      <td>20.344224</td>\n",
       "      <td>8.212203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.458389</td>\n",
       "      <td>110002</td>\n",
       "      <td>54.385737</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.369882</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.182299</td>\n",
       "      <td>39.015855</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.182299</td>\n",
       "      <td>9.458389</td>\n",
       "      <td>2.338060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.110972</td>\n",
       "      <td>110004</td>\n",
       "      <td>21.721631</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.887150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.833229</td>\n",
       "      <td>106.052669</td>\n",
       "      <td>3.833229</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.555486</td>\n",
       "      <td>5.110972</td>\n",
       "      <td>7.626311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>110009</td>\n",
       "      <td>48.921969</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.460985</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.494426</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.472132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.922331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.466639</td>\n",
       "      <td>110010</td>\n",
       "      <td>9.866555</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.333194</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.466639</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.466639</td>\n",
       "      <td>36.999581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>197.331097</td>\n",
       "      <td>2.466639</td>\n",
       "      <td>7.359796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 316 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ÚLCERA_GÁSTRICA_E_DUODENAL  MUNCOD  \\\n",
       "0                   28.481914  110001   \n",
       "1                    9.458389  110002   \n",
       "3                    5.110972  110004   \n",
       "8                    0.000000  110009   \n",
       "9                    2.466639  110010   \n",
       "\n",
       "   VEIAS_VARICOSAS_DAS_EXTREMIDADES_INFERIORES  VARICELA_E_HERPES_ZOSTER  \\\n",
       "0                                    40.688449                       0.0   \n",
       "1                                    54.385737                       0.0   \n",
       "3                                    21.721631                       0.0   \n",
       "8                                    48.921969                       0.0   \n",
       "9                                     9.866555                       0.0   \n",
       "\n",
       "   UROLITÍASE  TÉTANO_NEONATAL  TUBERC_INTEST_PERITÔNIO_GLÂNGL_MESENTÉRICOS  \\\n",
       "0  142.409570              NaN                                          NaN   \n",
       "1   15.369882              NaN                                          0.0   \n",
       "3   63.887150              NaN                                          NaN   \n",
       "8   24.460985              NaN                                          NaN   \n",
       "9   12.333194              NaN                                          0.0   \n",
       "\n",
       "   TUBERCULOSE_ÓSSEA_E_DAS_ARTICULAÇÕES  TUBERCULOSE_PULMONAR  \\\n",
       "0                                   NaN                   0.0   \n",
       "1                                   NaN                   0.0   \n",
       "3                                   NaN                   0.0   \n",
       "8                                   NaN                   0.0   \n",
       "9                                   0.0                   0.0   \n",
       "\n",
       "   TUBERCULOSE_MILIAR  ...  ANCILOSTOMÍASE  AMEBÍASE  \\\n",
       "0                 NaN  ...             NaN  0.000000   \n",
       "1                 0.0  ...             NaN  0.000000   \n",
       "3                 0.0  ...             NaN       NaN   \n",
       "8                 NaN  ...             NaN  0.000000   \n",
       "9                 0.0  ...             0.0  2.466639   \n",
       "\n",
       "   ALGUNS_TRANSTORNOS_ENVOLVENDO_MECANISMO_IMUNITÁRIO  \\\n",
       "0                                                NaN    \n",
       "1                                                0.0    \n",
       "3                                                0.0    \n",
       "8                                                NaN    \n",
       "9                                                NaN    \n",
       "\n",
       "   AFECÇ_HEMORRÁG_E_OUTR_DOENÇ_SANG_E_ÓRG_HEMATOPOÉT  \\\n",
       "0                                          44.757293   \n",
       "1                                           1.182299   \n",
       "3                                           3.833229   \n",
       "8                                           3.494426   \n",
       "9                                           2.466639   \n",
       "\n",
       "   ACID_VASCULAR_CEREBR_NÃO_ESPEC_HEMORRÁG_OU_ISQUÊM  \\\n",
       "0                                          40.688449   \n",
       "1                                          39.015855   \n",
       "3                                         106.052669   \n",
       "8                                           0.000000   \n",
       "9                                          36.999581   \n",
       "\n",
       "   ACID_VASCULAR_CEREBR_ISQUÊM_TRANSIT_E_SÍNDR_CORREL  \\\n",
       "0                                          32.550759    \n",
       "1                                           0.000000    \n",
       "3                                           3.833229    \n",
       "8                                          17.472132    \n",
       "9                                           0.000000    \n",
       "\n",
       "   ABORTO_POR_RAZÕES_MÉDICAS  ABORTO_ESPONTÂNEO   PREVIOUS      RATE  \n",
       "0                        NaN         126.134191  20.344224  8.212203  \n",
       "1                        0.0           1.182299   9.458389  2.338060  \n",
       "3                        0.0           2.555486   5.110972  7.626311  \n",
       "8                        0.0           0.000000   0.000000  6.922331  \n",
       "9                        0.0         197.331097   2.466639  7.359796  \n",
       "\n",
       "[5 rows x 316 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.DataFrame()\n",
    "percentage_valid_values = 0.8\n",
    "for i in range(0,len(years)-2):\n",
    "    col_year_suicide = \"RATE_\" + years[i+1]\n",
    "    col_year_prev = \"RATE_\" + years[i]\n",
    "    year_df = suicide[[col_year_prev, col_year_suicide, \"MUNCOD\"]]\n",
    "    year_df = year_df.rename(columns={col_year_suicide: \"RATE\"})\n",
    "    year_df = year_df.rename(columns={col_year_prev: \"PREVIOUS\"})\n",
    "    for disease in disease_list:\n",
    "        col_year_disease = \"RATE_\" + years[i]\n",
    "        disease_df = pd.read_csv(path + disease + \".csv\", sep=',', index_col=0)\n",
    "        disease_df = disease_df[[col_year_disease, \"MUNCOD\"]]\n",
    "        disease_df = disease_df.rename(columns={col_year_disease: disease})\n",
    "\n",
    "        year_df = pd.merge(disease_df, year_df, left_on=\"MUNCOD\", right_on=\"MUNCOD\", how='right')\n",
    "    N = int(year_df.shape[1]*percentage_valid_values)  \n",
    "    year_df = year_df.dropna(thresh=N)\n",
    "    train_df = pd.concat([train_df, year_df])\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ÚLCERA_GÁSTRICA_E_DUODENAL</th>\n",
       "      <th>VEIAS_VARICOSAS_DAS_EXTREMIDADES_INFERIORES</th>\n",
       "      <th>VARICELA_E_HERPES_ZOSTER</th>\n",
       "      <th>UROLITÍASE</th>\n",
       "      <th>TÉTANO_NEONATAL</th>\n",
       "      <th>TUBERC_INTEST_PERITÔNIO_GLÂNGL_MESENTÉRICOS</th>\n",
       "      <th>TUBERCULOSE_ÓSSEA_E_DAS_ARTICULAÇÕES</th>\n",
       "      <th>TUBERCULOSE_PULMONAR</th>\n",
       "      <th>TUBERCULOSE_MILIAR</th>\n",
       "      <th>TUBERCULOSE_DO_SISTEMA_NERVOSO</th>\n",
       "      <th>...</th>\n",
       "      <th>PR</th>\n",
       "      <th>RJ</th>\n",
       "      <th>RN</th>\n",
       "      <th>RO</th>\n",
       "      <th>RR</th>\n",
       "      <th>RS</th>\n",
       "      <th>SC</th>\n",
       "      <th>SE</th>\n",
       "      <th>SP</th>\n",
       "      <th>TO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.481914</td>\n",
       "      <td>40.688449</td>\n",
       "      <td>0.0</td>\n",
       "      <td>142.409570</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.458389</td>\n",
       "      <td>54.385737</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.369882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.110972</td>\n",
       "      <td>21.721631</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.887150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>48.921969</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.460985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.466639</td>\n",
       "      <td>9.866555</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.333194</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 342 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ÚLCERA_GÁSTRICA_E_DUODENAL  VEIAS_VARICOSAS_DAS_EXTREMIDADES_INFERIORES  \\\n",
       "0                   28.481914                                    40.688449   \n",
       "1                    9.458389                                    54.385737   \n",
       "3                    5.110972                                    21.721631   \n",
       "8                    0.000000                                    48.921969   \n",
       "9                    2.466639                                     9.866555   \n",
       "\n",
       "   VARICELA_E_HERPES_ZOSTER  UROLITÍASE  TÉTANO_NEONATAL  \\\n",
       "0                       0.0  142.409570              0.0   \n",
       "1                       0.0   15.369882              0.0   \n",
       "3                       0.0   63.887150              0.0   \n",
       "8                       0.0   24.460985              0.0   \n",
       "9                       0.0   12.333194              0.0   \n",
       "\n",
       "   TUBERC_INTEST_PERITÔNIO_GLÂNGL_MESENTÉRICOS  \\\n",
       "0                                          0.0   \n",
       "1                                          0.0   \n",
       "3                                          0.0   \n",
       "8                                          0.0   \n",
       "9                                          0.0   \n",
       "\n",
       "   TUBERCULOSE_ÓSSEA_E_DAS_ARTICULAÇÕES  TUBERCULOSE_PULMONAR  \\\n",
       "0                                   0.0                   0.0   \n",
       "1                                   0.0                   0.0   \n",
       "3                                   0.0                   0.0   \n",
       "8                                   0.0                   0.0   \n",
       "9                                   0.0                   0.0   \n",
       "\n",
       "   TUBERCULOSE_MILIAR  TUBERCULOSE_DO_SISTEMA_NERVOSO  ...  PR  RJ  RN  RO  \\\n",
       "0                 0.0                             0.0  ...   0   0   0   1   \n",
       "1                 0.0                             0.0  ...   0   0   0   1   \n",
       "3                 0.0                             0.0  ...   0   0   0   1   \n",
       "8                 0.0                             0.0  ...   0   0   0   1   \n",
       "9                 0.0                             0.0  ...   0   0   0   1   \n",
       "\n",
       "   RR  RS  SC  SE  SP  TO  \n",
       "0   0   0   0   0   0   0  \n",
       "1   0   0   0   0   0   0  \n",
       "3   0   0   0   0   0   0  \n",
       "8   0   0   0   0   0   0  \n",
       "9   0   0   0   0   0   0  \n",
       "\n",
       "[5 rows x 342 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill NaN values with 0\n",
    "train_df = train_df.fillna(0)\n",
    "\n",
    "# Get MUNCOD from UF\n",
    "train_df['UF'] = train_df['MUNCOD'] / 10000\n",
    "train_df['UF'] = train_df['UF'].astype(int)\n",
    "train_df['UF'].replace(dict_uf_cod, inplace=True)\n",
    "dummy = pd.get_dummies(train_df['UF'])\n",
    "train_df = pd.concat([train_df, dummy], axis=1)\n",
    "train_df = train_df.drop(['MUNCOD', 'UF'], axis=1)\n",
    "\n",
    "# Removing outliers\n",
    "train_df = train_df[(np.abs(stats.zscore(train_df[\"RATE\"])) < 3)] \n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"train_data_regression.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting testing data (2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ÚLCERA_GÁSTRICA_E_DUODENAL</th>\n",
       "      <th>MUNCOD</th>\n",
       "      <th>VEIAS_VARICOSAS_DAS_EXTREMIDADES_INFERIORES</th>\n",
       "      <th>VARICELA_E_HERPES_ZOSTER</th>\n",
       "      <th>UROLITÍASE</th>\n",
       "      <th>TÉTANO_NEONATAL</th>\n",
       "      <th>TUBERC_INTEST_PERITÔNIO_GLÂNGL_MESENTÉRICOS</th>\n",
       "      <th>TUBERCULOSE_ÓSSEA_E_DAS_ARTICULAÇÕES</th>\n",
       "      <th>TUBERCULOSE_PULMONAR</th>\n",
       "      <th>TUBERCULOSE_MILIAR</th>\n",
       "      <th>...</th>\n",
       "      <th>ANCILOSTOMÍASE</th>\n",
       "      <th>AMEBÍASE</th>\n",
       "      <th>ALGUNS_TRANSTORNOS_ENVOLVENDO_MECANISMO_IMUNITÁRIO</th>\n",
       "      <th>AFECÇ_HEMORRÁG_E_OUTR_DOENÇ_SANG_E_ÓRG_HEMATOPOÉT</th>\n",
       "      <th>ACID_VASCULAR_CEREBR_NÃO_ESPEC_HEMORRÁG_OU_ISQUÊM</th>\n",
       "      <th>ACID_VASCULAR_CEREBR_ISQUÊM_TRANSIT_E_SÍNDR_CORREL</th>\n",
       "      <th>ABORTO_POR_RAZÕES_MÉDICAS</th>\n",
       "      <th>ABORTO_ESPONTÂNEO</th>\n",
       "      <th>PREVIOUS</th>\n",
       "      <th>RATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.656406</td>\n",
       "      <td>110001</td>\n",
       "      <td>23.587687</td>\n",
       "      <td>19.656406</td>\n",
       "      <td>231.945591</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.793844</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.037937</td>\n",
       "      <td>70.763062</td>\n",
       "      <td>3.931281</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.656406</td>\n",
       "      <td>11.793844</td>\n",
       "      <td>4.316485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.384182</td>\n",
       "      <td>110002</td>\n",
       "      <td>13.973636</td>\n",
       "      <td>1.863152</td>\n",
       "      <td>32.605152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.863152</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.810424</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.042061</td>\n",
       "      <td>71.731334</td>\n",
       "      <td>3.726303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.126182</td>\n",
       "      <td>9.315758</td>\n",
       "      <td>1.883807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.038833</td>\n",
       "      <td>110004</td>\n",
       "      <td>20.337374</td>\n",
       "      <td>3.389562</td>\n",
       "      <td>42.934457</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.259708</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.298541</td>\n",
       "      <td>73.440519</td>\n",
       "      <td>1.129854</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.649271</td>\n",
       "      <td>5.649271</td>\n",
       "      <td>9.432516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.027551</td>\n",
       "      <td>110009</td>\n",
       "      <td>12.110203</td>\n",
       "      <td>3.027551</td>\n",
       "      <td>6.055101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.082652</td>\n",
       "      <td>45.413261</td>\n",
       "      <td>39.358159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.137754</td>\n",
       "      <td>9.082652</td>\n",
       "      <td>6.240834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.107437</td>\n",
       "      <td>110010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.107437</td>\n",
       "      <td>14.752060</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.107437</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.107437</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.107437</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.074371</td>\n",
       "      <td>18.966934</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>219.173463</td>\n",
       "      <td>8.429749</td>\n",
       "      <td>13.105301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 316 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ÚLCERA_GÁSTRICA_E_DUODENAL  MUNCOD  \\\n",
       "0                   19.656406  110001   \n",
       "1                    8.384182  110002   \n",
       "3                    9.038833  110004   \n",
       "8                    3.027551  110009   \n",
       "9                    2.107437  110010   \n",
       "\n",
       "   VEIAS_VARICOSAS_DAS_EXTREMIDADES_INFERIORES  VARICELA_E_HERPES_ZOSTER  \\\n",
       "0                                    23.587687                 19.656406   \n",
       "1                                    13.973636                  1.863152   \n",
       "3                                    20.337374                  3.389562   \n",
       "8                                    12.110203                  3.027551   \n",
       "9                                     0.000000                  2.107437   \n",
       "\n",
       "   UROLITÍASE  TÉTANO_NEONATAL  TUBERC_INTEST_PERITÔNIO_GLÂNGL_MESENTÉRICOS  \\\n",
       "0  231.945591              NaN                                          NaN   \n",
       "1   32.605152              NaN                                     0.000000   \n",
       "3   42.934457              NaN                                          NaN   \n",
       "8    6.055101              NaN                                          NaN   \n",
       "9   14.752060              NaN                                     2.107437   \n",
       "\n",
       "   TUBERCULOSE_ÓSSEA_E_DAS_ARTICULAÇÕES  TUBERCULOSE_PULMONAR  \\\n",
       "0                                   NaN             11.793844   \n",
       "1                                   NaN              1.863152   \n",
       "3                                   NaN              0.000000   \n",
       "8                                   NaN              0.000000   \n",
       "9                                   0.0              2.107437   \n",
       "\n",
       "   TUBERCULOSE_MILIAR  ...  ANCILOSTOMÍASE   AMEBÍASE  \\\n",
       "0                 NaN  ...             NaN   0.000000   \n",
       "1            0.000000  ...             NaN  29.810424   \n",
       "3            2.259708  ...             NaN        NaN   \n",
       "8                 NaN  ...             NaN   0.000000   \n",
       "9            0.000000  ...             0.0   2.107437   \n",
       "\n",
       "   ALGUNS_TRANSTORNOS_ENVOLVENDO_MECANISMO_IMUNITÁRIO  \\\n",
       "0                                                NaN    \n",
       "1                                                0.0    \n",
       "3                                                0.0    \n",
       "8                                                NaN    \n",
       "9                                                NaN    \n",
       "\n",
       "   AFECÇ_HEMORRÁG_E_OUTR_DOENÇ_SANG_E_ÓRG_HEMATOPOÉT  \\\n",
       "0                                          55.037937   \n",
       "1                                          13.042061   \n",
       "3                                          11.298541   \n",
       "8                                           9.082652   \n",
       "9                                          21.074371   \n",
       "\n",
       "   ACID_VASCULAR_CEREBR_NÃO_ESPEC_HEMORRÁG_OU_ISQUÊM  \\\n",
       "0                                          70.763062   \n",
       "1                                          71.731334   \n",
       "3                                          73.440519   \n",
       "8                                          45.413261   \n",
       "9                                          18.966934   \n",
       "\n",
       "   ACID_VASCULAR_CEREBR_ISQUÊM_TRANSIT_E_SÍNDR_CORREL  \\\n",
       "0                                           3.931281    \n",
       "1                                           3.726303    \n",
       "3                                           1.129854    \n",
       "8                                          39.358159    \n",
       "9                                           0.000000    \n",
       "\n",
       "   ABORTO_POR_RAZÕES_MÉDICAS  ABORTO_ESPONTÂNEO   PREVIOUS       RATE  \n",
       "0                        NaN          19.656406  11.793844   4.316485  \n",
       "1                        0.0          39.126182   9.315758   1.883807  \n",
       "3                        0.0           5.649271   5.649271   9.432516  \n",
       "8                        0.0          15.137754   9.082652   6.240834  \n",
       "9                        0.0         219.173463   8.429749  13.105301  \n",
       "\n",
       "[5 rows x 316 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage_valid_values = 0.8\n",
    "col_year_suicide = \"RATE_18\"\n",
    "col_year_prev = \"RATE_17\"\n",
    "test_df = suicide[[col_year_prev, col_year_suicide, \"MUNCOD\"]]\n",
    "test_df = test_df.rename(columns={col_year_suicide: \"RATE\"})\n",
    "test_df = test_df.rename(columns={col_year_prev: \"PREVIOUS\"})\n",
    "for disease in disease_list:\n",
    "    col_year_disease = \"RATE_17\"\n",
    "    disease_df = pd.read_csv(path + disease + \".csv\", sep=',', index_col=0)\n",
    "    disease_df = disease_df[[col_year_disease, \"MUNCOD\"]]\n",
    "    disease_df = disease_df.rename(columns={col_year_disease: disease})\n",
    "\n",
    "    test_df = pd.merge(disease_df, test_df, left_on=\"MUNCOD\", right_on=\"MUNCOD\", how='right')\n",
    "N = int(test_df.shape[1]*percentage_valid_values)  \n",
    "test_df = test_df.dropna(thresh=N)\n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv(\"test_data_regression.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"df_regression.csv\",index_col=0)\n",
    "train_df = pd.read_csv(\"train_data_regression.csv\", index_col=0)\n",
    "test_df = pd.read_csv(\"test_data_regression.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9640, 341)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(columns=[\"RATE\"])\n",
    "y = df[\"RATE\"]\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining some functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcUpMetrics(y_pred,y_test,X_test):\n",
    "    up_df = pd.DataFrame({\"Pred\": y_pred, \"Real\": y_test, \"Previous\": X_test[\"PREVIOUS\"]})\n",
    "    up_df[\"UP\"] = up_df[\"Previous\"] < up_df[\"Real\"]\n",
    "    up_df[\"UP_PRED\"] = up_df[\"Previous\"] < up_df[\"Pred\"]\n",
    "    up_df[\"UP\"] = up_df[\"UP\"].astype(int)\n",
    "    up_df[\"UP_PRED\"] = up_df[\"UP_PRED\"].astype(int)\n",
    "    return metrics.recall_score(up_df[\"UP\"], up_df[\"UP_PRED\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_feat_importance(feature_importance_list):\n",
    "    final_feat_df = pd.DataFrame()\n",
    "    for i, feat_df in enumerate(feature_importance_list):\n",
    "        feat_df = feat_df.rename(columns={\"Importance\": i})\n",
    "        if final_feat_df.empty:\n",
    "            final_feat_df = feat_df\n",
    "        else:\n",
    "            final_feat_df = pd.merge(final_feat_df, feat_df, on=\"Feature\")\n",
    "    final_feat_df[\"Avg_importance\"] = final_feat_df.sum(axis=1)/(final_feat_df.shape[1] -1)\n",
    "    final_feat_df = final_feat_df[[\"Feature\", \"Avg_importance\"]]\n",
    "    return final_feat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cor_feature_selector(X,y,corr_min_value):\n",
    "    cor_list = []\n",
    "    for i in list(X.columns):\n",
    "        cor = np.corrcoef(X[i], y)[0,1]\n",
    "        cor_list.append([i, cor])\n",
    "    cor_feature = [x[0] for x in cor_list if abs(x[1]) > corr_min_value]\n",
    "    print(len(cor_feature), \"selected features (correlation)\")\n",
    "    return cor_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_train, y_test, y_pred, y_pred_train, scores=None):\n",
    "    rmse_train = np.sqrt(metrics.mean_squared_error(y_pred_train,y_train))\n",
    "    rmse_test = np.sqrt(metrics.mean_squared_error(y_pred,y_test))\n",
    "    rmse_baseline_train = np.sqrt(metrics.mean_squared_error(X_train[\"PREVIOUS\"],y_train))\n",
    "    rmse_baseline_test = np.sqrt(metrics.mean_squared_error(X_test[\"PREVIOUS\"],y_test))\n",
    "    up_down_train = calcUpMetrics(y_pred_train,y_train,X_train)\n",
    "    up_down_test = calcUpMetrics(y_pred,y_test,X_test)\n",
    "                                 \n",
    "    print(\"RMSE Train:\", rmse_train)\n",
    "    print(\"RMSE Test:\", rmse_test)\n",
    "    print(\"RMSE Baseline Train:\", rmse_baseline_train)\n",
    "    print(\"RMSE Baseline Test:\", rmse_baseline_test)\n",
    "    print(\"Up/Down Recall Train:\", up_down_train)\n",
    "    print(\"Up/Down Recall Test:\", up_down_test)\n",
    "    if scores is not None:\n",
    "        scores = scores.append({'rmse_train':rmse_train, 'rmse_test':rmse_test, \"rmse_baseline_train\": rmse_baseline_train, \"rmse_baseline_test\": rmse_baseline_test, \"up_down_train\": up_down_train, \"up_down_test\": up_down_test},ignore_index=True)\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feat = 50\n",
    "corr_min_value = 0.05\n",
    "all_models_scores = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "### No Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============== RUN 1 ===============\n",
      "# Feature Selection: correlation\n",
      "121 selected features (correlation)\n",
      "# Bayesian Optimization\n",
      "# Fitting the model\n",
      "# Making predictions\n",
      "# Calculating metrics\n",
      "RMSE Train: 1.8706874725355613\n",
      "RMSE Test: 4.5559191861286665\n",
      "RMSE Baseline Train: 5.587001133045161\n",
      "RMSE Baseline Test: 5.708701552449413\n",
      "Up/Down Recall Train: 0.9659304511278195\n",
      "Up/Down Recall Test: 0.8090737240075614\n",
      "# Get Feature Importance\n",
      "\n",
      "\n",
      "=============== RUN 2 ===============\n",
      "# Feature Selection: correlation\n",
      "111 selected features (correlation)\n",
      "# Bayesian Optimization\n",
      "# Fitting the model\n",
      "# Making predictions\n",
      "# Calculating metrics\n",
      "RMSE Train: 1.8741405315300752\n",
      "RMSE Test: 4.272846119610831\n",
      "RMSE Baseline Train: 5.6053569012030104\n",
      "RMSE Baseline Test: 5.636266148619417\n",
      "Up/Down Recall Train: 0.970311027332705\n",
      "Up/Down Recall Test: 0.811214953271028\n",
      "# Get Feature Importance\n",
      "\n",
      "\n",
      "=============== RUN 3 ===============\n",
      "# Feature Selection: correlation\n",
      "119 selected features (correlation)\n",
      "# Bayesian Optimization\n",
      "# Fitting the model\n",
      "# Making predictions\n",
      "# Calculating metrics\n",
      "RMSE Train: 1.8334931899865756\n",
      "RMSE Test: 4.483437446593925\n",
      "RMSE Baseline Train: 5.631034413192984\n",
      "RMSE Baseline Test: 5.532938261654057\n",
      "Up/Down Recall Train: 0.9707122774133083\n",
      "Up/Down Recall Test: 0.8107074569789675\n",
      "# Get Feature Importance\n",
      "\n",
      "\n",
      "=============== RUN 4 ===============\n",
      "# Feature Selection: correlation\n",
      "119 selected features (correlation)\n",
      "# Bayesian Optimization\n",
      "# Fitting the model\n",
      "# Making predictions\n",
      "# Calculating metrics\n",
      "RMSE Train: 1.886950594204161\n",
      "RMSE Test: 4.417378947187657\n",
      "RMSE Baseline Train: 5.632256148839671\n",
      "RMSE Baseline Test: 5.527961898653148\n",
      "Up/Down Recall Train: 0.970285446888161\n",
      "Up/Down Recall Test: 0.8028846153846154\n",
      "# Get Feature Importance\n",
      "\n",
      "\n",
      "=============== RUN 5 ===============\n",
      "# Feature Selection: correlation\n",
      "111 selected features (correlation)\n",
      "# Bayesian Optimization\n",
      "# Fitting the model\n",
      "# Making predictions\n",
      "# Calculating metrics\n",
      "RMSE Train: 1.9023939413875144\n",
      "RMSE Test: 4.255800710073397\n",
      "RMSE Baseline Train: 5.60197594767346\n",
      "RMSE Baseline Test: 5.649695742629174\n",
      "Up/Down Recall Train: 0.9679639297579496\n",
      "Up/Down Recall Test: 0.8163636363636364\n",
      "# Get Feature Importance\n",
      "\n",
      "\n",
      "=============== SUMMARY ===============\n",
      "# Average Metrics\n",
      "rmse_train             1.873533\n",
      "rmse_test              4.397076\n",
      "rmse_baseline_train    5.611525\n",
      "rmse_baseline_test     5.611113\n",
      "up_down_train          0.969041\n",
      "up_down_test           0.810049\n",
      "dtype: float64\n",
      "# Average Feature Importance\n",
      "                                              Feature  Avg_importance\n",
      "0                                            PREVIOUS        0.112572\n",
      "1   BRONQUITE_ENFISEMA_E_OUTR_DOENÇ_PULM_OBSTR_CRÔNIC        0.024084\n",
      "2                                                  RS        0.031217\n",
      "3                                 DOENÇAS_DO_APÊNDICE        0.014951\n",
      "4   NEOPLASIA_MALIGNA_DE_TRAQUÉIA_BRÔNQUIOS_E_PULMÕES        0.014621\n",
      "5                     TRANSTORNOS_DE_HUMOR_[AFETIVOS]        0.012151\n",
      "6       TRANSTORNOS_DE_CONDUÇÃO_E_ARRITMIAS_CARDÍACAS        0.017205\n",
      "7                           COLELITÍASE_E_COLECISTITE        0.012358\n",
      "8                  OUTRAS_NEOPLASIAS_MALIGNAS_DA_PELE        0.012978\n",
      "9   TRANST_MENTAIS_COMPORT_DEV_USO_OUTR_SUBST_PSICOAT        0.012484\n",
      "10          OUTRAS_DOENÇAS_DOS_INTESTINOS_E_PERITÔNIO        0.011179\n",
      "11                                         UROLITÍASE        0.011897\n",
      "12                             PARTO_ÚNICO_ESPONTÂNEO        0.011091\n",
      "13               OUTRAS_DOENÇAS_ISQUÊMICAS_DO_CORAÇÃO        0.011845\n",
      "14  TRANST_MENTAIS_E_COMPORTAMENTAIS_DEV_USO_DE_ÁL...        0.010691\n",
      "15                     OUTROS_TRANSTRONOS_ARTICULARES        0.009111\n",
      "16                                     OUTRAS_HÉRNIAS        0.010811\n",
      "17  NEOPL_MALIG_OUTR_LOCALIZ_MAL_DEF_SECUN_E_NÃO_E...        0.010593\n",
      "18                                 LEIOMIOMA_DO_ÚTERO        0.009932\n",
      "19     PANCREATITE_AGUDA_E_OUTRAS_DOENÇAS_DO_PÂNCREAS        0.009932\n",
      "\n",
      "Total run time: 6180.881489515305\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "scores = pd.DataFrame({\"rmse_train\": [], \"rmse_test\": [], \"rmse_baseline_train\": [], \"rmse_baseline_test\": [], \"up_down_train\": [], \"up_down_test\": []})\n",
    "feature_importance_list = []\n",
    "count = 1\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print(\"=============== RUN {} ===============\".format(count))\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    print(\"# Feature Selection: correlation\")\n",
    "    selected_cor_features = cor_feature_selector(X_train,y_train,corr_min_value)\n",
    "    X_train = X_train[selected_cor_features]\n",
    "    X_test = X_test[selected_cor_features]\n",
    "    \n",
    "    print(\"# Bayesian Optimization\")\n",
    "    def train_model(params):\n",
    "        n_estimators = params[0]\n",
    "        max_depth = params[1]\n",
    "        min_samples_leaf = params[2]\n",
    "        max_features = params[3]\n",
    "\n",
    "        xf_train_params,xf_val,yf_train_params,yf_val = train_test_split(X_train,y_train,test_size=0.33,random_state=42)\n",
    "\n",
    "        model = RandomForestRegressor(n_jobs=-1, random_state=42,n_estimators=n_estimators, \n",
    "                                      max_depth=max_depth,min_samples_leaf=min_samples_leaf,max_features=max_features)\n",
    "\n",
    "        model.fit(xf_train_params,yf_train_params)\n",
    "        yf_pred = model.predict(xf_val)\n",
    "\n",
    "        return np.sqrt(metrics.mean_squared_error(yf_val, yf_pred))\n",
    "    space = [\n",
    "        (5,1000), #n_estimators\n",
    "        (3,30), #max_depth\n",
    "        (2,200), #min_samples_leaf\n",
    "        (0.25,1.00) #max_features\n",
    "    ]\n",
    "    resultado_gp = gp_minimize(train_model, space, random_state=42, verbose=0, n_calls=30, n_random_starts=10)\n",
    "    \n",
    "    print(\"# Fitting the model\")\n",
    "    regressor = RandomForestRegressor(n_jobs=-1, random_state=42,n_estimators=resultado_gp.x[0], \n",
    "                                  max_depth=resultado_gp.x[1],min_samples_leaf=resultado_gp.x[2],max_features=resultado_gp.x[3])\n",
    "    regressor.fit(X_train,y_train)\n",
    "    \n",
    "    print(\"# Making predictions\")\n",
    "    y_pred = regressor.predict(X_test) \n",
    "    y_pred_train = regressor.predict(X_train)\n",
    "    \n",
    "    print(\"# Calculating metrics\")\n",
    "    scores = calculate_metrics(y_train, y_test, y_pred, y_pred_train, scores)\n",
    "    \n",
    "    print(\"# Get Feature Importance\")\n",
    "    importance = regressor.feature_importances_\n",
    "    feature_importance_list.append(pd.DataFrame({\"Feature\": X_train.columns, \"Importance\": importance}).sort_values(by=\"Importance\", ascending=False))\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    count += 1\n",
    "print(\"=============== SUMMARY Random Forest ===============\")\n",
    "print(\"# Average Metrics\")\n",
    "print(scores.mean())\n",
    "all_models_scores[\"Random Forest\"] = scores\n",
    "print(\"# Average Feature Importance\")\n",
    "final_feat_df = get_average_feat_importance(feature_importance_list)\n",
    "print(final_feat_df.head(20))\n",
    "end = time.time()\n",
    "\n",
    "print(\"\\nTotal run time:\", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(columns=[\"RATE\"])\n",
    "y_train = train_df[\"RATE\"]\n",
    "\n",
    "selected_cor_features = cor_feature_selector(X_train,y_train,corr_min_value)\n",
    "\n",
    "with open('selected_cor_features', 'wb') as fp:\n",
    "    pickle.dump(selected_cor_features, fp)\n",
    "    \n",
    "X_train = X_train[selected_cor_features]\n",
    "\n",
    "def train_model(params):\n",
    "    n_estimators = params[0]\n",
    "    max_depth = params[1]\n",
    "    min_samples_leaf = params[2]\n",
    "    max_features = params[3]\n",
    "\n",
    "    xf_train_params,xf_val,yf_train_params,yf_val = train_test_split(X_train,y_train,test_size=0.33,random_state=42)\n",
    "\n",
    "    model = RandomForestRegressor(n_jobs=-1, random_state=42,n_estimators=n_estimators, \n",
    "                                  max_depth=max_depth,min_samples_leaf=min_samples_leaf,max_features=max_features)\n",
    "\n",
    "    model.fit(xf_train_params,yf_train_params)\n",
    "    yf_pred = model.predict(xf_val)\n",
    "\n",
    "    return np.sqrt(metrics.mean_squared_error(yf_val, yf_pred))\n",
    "space = [\n",
    "    (5,1000), #n_estimators\n",
    "    (3,30), #max_depth\n",
    "    (2,200), #min_samples_leaf\n",
    "    (0.25,1.00) #max_features\n",
    "]\n",
    "resultado_gp = gp_minimize(train_model, space, random_state=42, verbose=0, n_calls=30, n_random_starts=10)\n",
    "\n",
    "regressor = RandomForestRegressor(n_jobs=-1, random_state=42,n_estimators=resultado_gp.x[0], \n",
    "                              max_depth=resultado_gp.x[1],min_samples_leaf=resultado_gp.x[2],max_features=resultado_gp.x[3])\n",
    "regressor.fit(X_train,y_train)\n",
    "\n",
    "filename = root + 'Dashboard/Models/sav/random_forest_regression.sav'\n",
    "pickle.dump(regressor, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=42, test_size=1/5)\n",
    "\n",
    "print(\"# Feature Selection: correlation\")\n",
    "selected_cor_features = cor_feature_selector(X_train,y_train,corr_min_value)\n",
    "X_train = X_train[selected_cor_features]\n",
    "X_test = X_test[selected_cor_features]\n",
    "\n",
    "print(\"# Bayesian Optimization\")\n",
    "def train_model(params):\n",
    "    n_estimators = params[0]\n",
    "    max_depth = params[1]\n",
    "    min_samples_leaf = params[2]\n",
    "    max_features = params[3]\n",
    "\n",
    "    xf_train_params,xf_val,yf_train_params,yf_val = train_test_split(X_train,y_train,test_size=0.33,random_state=42)\n",
    "\n",
    "    model = RandomForestRegressor(n_jobs=-1, random_state=42,n_estimators=n_estimators, \n",
    "                                  max_depth=max_depth,min_samples_leaf=min_samples_leaf,max_features=max_features)\n",
    "\n",
    "    model.fit(xf_train_params,yf_train_params)\n",
    "    yf_pred = model.predict(xf_val)\n",
    "\n",
    "    return np.sqrt(metrics.mean_squared_error(yf_val, yf_pred))\n",
    "space = [\n",
    "    (5,1000), #n_estimators\n",
    "    (3,30), #max_depth\n",
    "    (2,200), #min_samples_leaf\n",
    "    (0.25,1.00) #max_features\n",
    "]\n",
    "resultado_gp = gp_minimize(train_model, space, random_state=42, verbose=0, n_calls=30, n_random_starts=10)\n",
    "\n",
    "print(\"# Fitting the model\")\n",
    "regressor = RandomForestRegressor(n_jobs=-1, random_state=42,n_estimators=resultado_gp.x[0], \n",
    "                              max_depth=resultado_gp.x[1],min_samples_leaf=resultado_gp.x[2],max_features=resultado_gp.x[3])\n",
    "regressor.fit(X_train,y_train)\n",
    "\n",
    "print(\"# Making predictions\")\n",
    "y_pred = regressor.predict(X_test) \n",
    "y_pred_train = regressor.predict(X_train)\n",
    "\n",
    "print(\"# Calculating metrics\")\n",
    "calculate_metrics(y_train, y_test, y_pred, y_pred_train)\n",
    "\n",
    "print(\"# Get Feature Importance\")\n",
    "importance = regressor.feature_importances_\n",
    "print(pd.DataFrame({\"Feature\": X_train.columns, \"Importance\": importance}).sort_values(by=\"Importance\", ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(regressor)\n",
    "\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "shap.summary_plot(shap_values[1], X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP Individual Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_df.loc[test_df['MUNCOD'] == 355030][\"RATE\"])\n",
    "\n",
    "data_for_prediction = test_df.loc[test_df['MUNCOD'] == 355030].drop(columns=[\"MUNCOD\", \"RATE\"])\n",
    "data_for_prediction_array = data_for_prediction.values.reshape(1, -1)\n",
    "\n",
    "explainer = shap.TreeExplainer(regressor)\n",
    "shap_values = explainer.shap_values(data_for_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "shap.force_plot(explainer.expected_value[1], shap_values[1], data_for_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "scores = pd.DataFrame({\"rmse_train\": [], \"rmse_test\": [], \"rmse_baseline_train\": [], \"rmse_baseline_test\": [], \"up_down_train\": [], \"up_down_test\": []})\n",
    "feature_importance_list = []\n",
    "count = 1\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print(\"=============== RUN {} ===============\".format(count))\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    print(\"# Feature Selection: correlation\")\n",
    "    selected_cor_features = cor_feature_selector(X_train,y_train,corr_min_value)\n",
    "    X_train = X_train[selected_cor_features]\n",
    "    X_test = X_test[selected_cor_features]\n",
    "    \n",
    "    print(\"# Bayesian Optimization\")\n",
    "    def train_model(params):\n",
    "        n_estimators = params[0]\n",
    "        learning_rate = params[1]\n",
    "\n",
    "        xf_train_params,xf_val,yf_train_params,yf_val = train_test_split(X_train,y_train,test_size=0.33,random_state=42)\n",
    "\n",
    "        model = AdaBoostRegressor(random_state=42,n_estimators=n_estimators, learning_rate=learning_rate)\n",
    "\n",
    "        model.fit(xf_train_params,yf_train_params)\n",
    "        yf_pred = model.predict(xf_val)\n",
    "\n",
    "        return np.sqrt(metrics.mean_squared_error(yf_val, yf_pred))\n",
    "    space = [\n",
    "        (30,200), #n_estimators\n",
    "        (0.01, 1) #learning_rate\n",
    "    ]\n",
    "    resultado_gp = gp_minimize(train_model, space, random_state=42, verbose=0, n_calls=30, n_random_starts=10)\n",
    "    \n",
    "    print(\"# Fitting the model\")\n",
    "    regressor = AdaBoostRegressor(random_state=42,n_estimators=resultado_gp.x[0], learning_rate=resultado_gp.x[1])\n",
    "    regressor.fit(X_train,y_train)\n",
    "    \n",
    "    print(\"# Making predictions\")\n",
    "    y_pred = regressor.predict(X_test) \n",
    "    y_pred_train = regressor.predict(X_train)\n",
    "    \n",
    "    print(\"# Calculating metrics\")\n",
    "    scores = calculate_metrics(y_train, y_test, y_pred, y_pred_train, scores)\n",
    "    \n",
    "    print(\"# Get Feature Importance\")\n",
    "    importance = regressor.feature_importances_\n",
    "    feature_importance_list.append(pd.DataFrame({\"Feature\": X_train.columns, \"Importance\": importance}).sort_values(by=\"Importance\", ascending=False))\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    count += 1\n",
    "print(\"=============== SUMMARY AdaBoost ===============\")\n",
    "print(\"# Average Metrics\")\n",
    "print(scores.mean())\n",
    "all_models_scores[\"AdaBoost\"] = scores\n",
    "print(\"# Average Feature Importance\")\n",
    "final_feat_df = get_average_feat_importance(feature_importance_list)\n",
    "print(final_feat_df.head(20))\n",
    "end = time.time()\n",
    "\n",
    "print(\"\\nTotal run time:\", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(columns=[\"RATE\"])\n",
    "y_train = train_df[\"RATE\"]\n",
    "\n",
    "with open('selected_cor_features', 'rb') as f:\n",
    "    selected_cor_features = pickle.load(f)\n",
    "    \n",
    "X_train = X_train[selected_cor_features]\n",
    "\n",
    "def train_model(params):\n",
    "    n_estimators = params[0]\n",
    "    learning_rate = params[1]\n",
    "\n",
    "    xf_train_params,xf_val,yf_train_params,yf_val = train_test_split(X_train,y_train,test_size=0.33,random_state=42)\n",
    "\n",
    "    model = AdaBoostRegressor(random_state=42,n_estimators=n_estimators, learning_rate=learning_rate)\n",
    "\n",
    "    model.fit(xf_train_params,yf_train_params)\n",
    "    yf_pred = model.predict(xf_val)\n",
    "\n",
    "    return np.sqrt(metrics.mean_squared_error(yf_val, yf_pred))\n",
    "space = [\n",
    "    (30,200), #n_estimators\n",
    "    (0.01, 1) #learning_rate\n",
    "]\n",
    "resultado_gp = gp_minimize(train_model, space, random_state=42, verbose=0, n_calls=30, n_random_starts=10)\n",
    "\n",
    "regressor = AdaBoostRegressor(random_state=42,n_estimators=resultado_gp.x[0], learning_rate=resultado_gp.x[1])\n",
    "regressor.fit(X_train,y_train)\n",
    "\n",
    "filename = root + 'Dashboard/Models/sav/adaboost_regression.sav'\n",
    "pickle.dump(regressor, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "start = time.time()\n",
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "scores = pd.DataFrame({\"rmse_train\": [], \"rmse_test\": [], \"rmse_baseline_train\": [], \"rmse_baseline_test\": [], \"up_down_train\": [], \"up_down_test\": []})\n",
    "feature_importance_list = []\n",
    "count = 1\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print(\"=============== RUN {} ===============\".format(count))\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    print(\"# Feature Selection: correlation\")\n",
    "    selected_cor_features = cor_feature_selector(X_train,y_train,corr_min_value)\n",
    "    X_train = X_train[selected_cor_features]\n",
    "    X_test = X_test[selected_cor_features]\n",
    "    \n",
    "    print(\"# Bayesian Optimization\")\n",
    "    def train_model(params):\n",
    "        n_estimators = params[0]\n",
    "        learning_rate = params[1]\n",
    "        max_depth = params[2]\n",
    "        min_samples_splits = params[3]\n",
    "        min_samples_leafs = params[4]\n",
    "\n",
    "        xf_train_params,xf_val,yf_train_params,yf_val = train_test_split(X_train,y_train,test_size=0.33,random_state=42)\n",
    "\n",
    "        model = GradientBoostingRegressor(random_state=42,n_estimators=n_estimators, learning_rate=learning_rate,\n",
    "                                          max_depth=max_depth,min_samples_splits=min_samples_splits,min_samples_leafs=min_samples_leafs)\n",
    "\n",
    "        model.fit(xf_train_params,yf_train_params)\n",
    "        yf_pred = model.predict(xf_val)\n",
    "\n",
    "        return np.sqrt(metrics.mean_squared_error(yf_val, yf_pred))\n",
    "    space = [\n",
    "        (30,200), #n_estimators\n",
    "        (0.01, 1), #learning_rate\n",
    "        (1,32), #max_depth\n",
    "        (0.1, 1) #min_samples_splits \n",
    "        (0.1, 0.5) #min_samples_leafs \n",
    "    ]\n",
    "    resultado_gp = gp_minimize(train_model, space, random_state=42, verbose=0, n_calls=30, n_random_starts=10)\n",
    "    \n",
    "    print(\"# Fitting the model\")\n",
    "    regressor = GradientBoostingRegressor(random_state=42,n_estimators=resultado_gp.x[0], learning_rate=resultado_gp.x[1],\n",
    "                                         max_depth=resultado_gp.x[2], min_samples_splits=resultado_gp.x[3], min_samples_leafs=resultado_gp.x[4])\n",
    "    regressor.fit(X_train,y_train)\n",
    "    \n",
    "    print(\"# Making predictions\")\n",
    "    y_pred = regressor.predict(X_test) \n",
    "    y_pred_train = regressor.predict(X_train)\n",
    "    \n",
    "    print(\"# Calculating metrics\")\n",
    "    scores = calculate_metrics(y_train, y_test, y_pred, y_pred_train, scores)\n",
    "    \n",
    "    print(\"# Get Feature Importance\")\n",
    "    importance = regressor.feature_importances_\n",
    "    feature_importance_list.append(pd.DataFrame({\"Feature\": X_train.columns, \"Importance\": importance}).sort_values(by=\"Importance\", ascending=False))\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    count += 1\n",
    "print(\"=============== SUMMARY Gradient Boosting ===============\")\n",
    "print(\"# Average Metrics\")\n",
    "print(scores.mean())\n",
    "all_models_scores[\"Gradient Boosting\"] = scores\n",
    "print(\"# Average Feature Importance\")\n",
    "final_feat_df = get_average_feat_importance(feature_importance_list)\n",
    "print(final_feat_df.head(20))\n",
    "end = time.time()\n",
    "\n",
    "print(\"\\nTotal run time:\", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(columns=[\"RATE\"])\n",
    "y_train = train_df[\"RATE\"]\n",
    "\n",
    "with open('selected_cor_features', 'rb') as f:\n",
    "    selected_cor_features = pickle.load(f)\n",
    "    \n",
    "X_train = X_train[selected_cor_features]\n",
    "\n",
    "def train_model(params):\n",
    "    n_estimators = params[0]\n",
    "    learning_rate = params[1]\n",
    "    max_depth = params[2]\n",
    "    min_samples_splits = params[3]\n",
    "    min_samples_leafs = params[4]\n",
    "\n",
    "    xf_train_params,xf_val,yf_train_params,yf_val = train_test_split(X_train,y_train,test_size=0.33,random_state=42)\n",
    "\n",
    "    model = GradientBoostingRegressor(random_state=42,n_estimators=n_estimators, learning_rate=learning_rate,\n",
    "                                      max_depth=max_depth,min_samples_splits=min_samples_splits,min_samples_leafs=min_samples_leafs)\n",
    "\n",
    "    model.fit(xf_train_params,yf_train_params)\n",
    "    yf_pred = model.predict(xf_val)\n",
    "\n",
    "    return np.sqrt(metrics.mean_squared_error(yf_val, yf_pred))\n",
    "space = [\n",
    "    (30,200), #n_estimators\n",
    "    (0.01, 1), #learning_rate\n",
    "    (1,32), #max_depth\n",
    "    (0.1, 1) #min_samples_splits \n",
    "    (0.1, 0.5) #min_samples_leafs \n",
    "]\n",
    "resultado_gp = gp_minimize(train_model, space, random_state=42, verbose=0, n_calls=30, n_random_starts=10)\n",
    "\n",
    "regressor = GradientBoostingRegressor(random_state=42,n_estimators=resultado_gp.x[0], learning_rate=resultado_gp.x[1],\n",
    "                                     max_depth=resultado_gp.x[2], min_samples_splits=resultado_gp.x[3], min_samples_leafs=resultado_gp.x[4])\n",
    "regressor.fit(X_train,y_train)\n",
    "\n",
    "filename = root + 'Dashboard/Models/sav/gradient_boost_regression.sav'\n",
    "pickle.dump(regressor, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MinMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "scores = pd.DataFrame({\"rmse_train\": [], \"rmse_test\": [], \"rmse_baseline_train\": [], \"rmse_baseline_test\": [], \"up_down_train\": [], \"up_down_test\": []})\n",
    "count = 1\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print(\"=============== RUN {} ===============\".format(count))\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    print(\"# Feature Selection: correlation\")\n",
    "    selected_cor_features = cor_feature_selector(X_train,y_train,corr_min_value)\n",
    "    X_train = X_train[selected_cor_features]\n",
    "    X_test = X_test[selected_cor_features]\n",
    "    \n",
    "    mm_x = MinMaxScaler()\n",
    "    mm_y = MinMaxScaler()\n",
    "    mm_x.fit(X_train)\n",
    "    mm_y.fit(y_train)\n",
    "    X_train = pd.DataFrame(mm_x.transform(X_train), index=X_train.index, columns=X_train.columns)\n",
    "    X_test = pd.DataFrame(mm_x.transform(X_test), index=X_test.index, columns=X_test.columns)\n",
    "    y_train = pd.DataFrame(mm_y.transform(y_train), index=y_train.index, columns=y_train.columns)\n",
    "    \n",
    "    print(\"# Bayesian Optimization\")\n",
    "    def train_model(params):\n",
    "        gamma = params[0]\n",
    "        C = params[1]\n",
    "\n",
    "        xf_train_params,xf_val,yf_train_params,yf_val = train_test_split(X_train,y_train,test_size=0.33,random_state=42)\n",
    "\n",
    "        model = SVR(gamma=gamma, C=C)\n",
    "\n",
    "        model.fit(xf_train_params,yf_train_params)\n",
    "        yf_pred = model.predict(xf_val)\n",
    "\n",
    "        return np.sqrt(metrics.mean_squared_error(yf_val, yf_pred))\n",
    "    space = [\n",
    "        (0.001,0.9), #gamma\n",
    "        (1,10000), #C\n",
    "    ]\n",
    "    resultado_gp = gp_minimize(train_model, space, random_state=42, verbose=0, n_calls=30, n_random_starts=10)\n",
    "    \n",
    "    print(\"# Fitting the model\")\n",
    "    regressor = SVR(gamma=resultado_gp.x[0], C=resultado_gp.x[1])\n",
    "    regressor.fit(X_train,y_train)\n",
    "    \n",
    "    print(\"# Making predictions\")\n",
    "    y_pred = regressor.predict(X_test) \n",
    "    y_pred_train = regressor.predict(X_train)\n",
    "    y_pred_train_reshaped = mm_y.inverse_transform(y_pred_train.reshape(-1,1))\n",
    "    y_pred_reshaped = mm_y.inverse_transform(y_pred.reshape(-1,1))\n",
    "    y_train_reshaped = mm_y.inverse_transform(y_train.reshape(-1,1))\n",
    "    \n",
    "    print(\"# Calculating metrics\")\n",
    "    scores = calculate_metrics(y_train_reshaped, y_test, y_pred_reshaped, y_pred_train_reshaped, scores)\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    count += 1\n",
    "print(\"=============== SUMMARY SVR MM ===============\")\n",
    "print(\"# Average Metrics\")\n",
    "print(scores.mean())\n",
    "all_models_scores[\"SVR MM\"] = scores\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"\\nTotal run time:\", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(columns=[\"RATE\"])\n",
    "y_train = train_df[\"RATE\"]\n",
    "\n",
    "with open('selected_cor_features', 'rb') as f:\n",
    "    selected_cor_features = pickle.load(f)\n",
    "    \n",
    "X_train = X_train[selected_cor_features]\n",
    "\n",
    "mm_x = MinMaxScaler()\n",
    "mm_y = MinMaxScaler()\n",
    "joblib.dump(mm_x, \"mm_x.save\")\n",
    "joblib.dump(mm_y, \"mm_y.save\")\n",
    "\n",
    "mm_x.fit(X_train)\n",
    "mm_y.fit(y_train)\n",
    "X_train = pd.DataFrame(mm_x.transform(X_train), index=X_train.index, columns=X_train.columns)\n",
    "X_test = pd.DataFrame(mm_x.transform(X_test), index=X_test.index, columns=X_test.columns)\n",
    "y_train = pd.DataFrame(mm_y.transform(y_train), index=y_train.index, columns=y_train.columns)\n",
    "\n",
    "def train_model(params):\n",
    "    gamma = params[0]\n",
    "    C = params[1]\n",
    "\n",
    "    xf_train_params,xf_val,yf_train_params,yf_val = train_test_split(X_train,y_train,test_size=0.33,random_state=42)\n",
    "\n",
    "    model = SVR(gamma=gamma, C=C)\n",
    "\n",
    "    model.fit(xf_train_params,yf_train_params)\n",
    "    yf_pred = model.predict(xf_val)\n",
    "\n",
    "    return np.sqrt(metrics.mean_squared_error(yf_val, yf_pred))\n",
    "space = [\n",
    "    (0.001,0.9), #gamma\n",
    "    (1,10000), #C\n",
    "]\n",
    "resultado_gp = gp_minimize(train_model, space, random_state=42, verbose=0, n_calls=30, n_random_starts=10)\n",
    "\n",
    "regressor = SVR(gamma=resultado_gp.x[0], C=resultado_gp.x[1])\n",
    "regressor.fit(X_train,y_train)\n",
    "\n",
    "filename = root + 'Dashboard/Models/sav/svr_mm_regression.sav'\n",
    "pickle.dump(regressor, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "scores = pd.DataFrame({\"rmse_train\": [], \"rmse_test\": [], \"rmse_baseline_train\": [], \"rmse_baseline_test\": [], \"up_down_train\": [], \"up_down_test\": []})\n",
    "count = 1\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print(\"=============== RUN {} ===============\".format(count))\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    print(\"# Feature Selection: correlation\")\n",
    "    selected_cor_features = cor_feature_selector(X_train,y_train,corr_min_value)\n",
    "    X_train = X_train[selected_cor_features]\n",
    "    X_test = X_test[selected_cor_features]\n",
    "    \n",
    "    sc_x = StandardScaler()\n",
    "    sc_y = StandardScaler()\n",
    "    sc_x.fit(X_train)\n",
    "    sc_y.fit(y_train)\n",
    "    X_train = pd.DataFrame(sc_x.transform(X_train), index=X_train.index, columns=X_train.columns)\n",
    "    X_test = pd.DataFrame(sc_x.transform(X_test), index=X_test.index, columns=X_test.columns)\n",
    "    y_train = pd.DataFrame(sc_y.transform(y_train), index=y_train.index, columns=y_train.columns)\n",
    "    \n",
    "    print(\"# Bayesian Optimization\")\n",
    "    def train_model(params):\n",
    "        gamma = params[0]\n",
    "        C = params[1]\n",
    "\n",
    "        xf_train_params,xf_val,yf_train_params,yf_val = train_test_split(X_train,y_train,test_size=0.33,random_state=42)\n",
    "\n",
    "        model = SVR(gamma=gamma, C=C)\n",
    "\n",
    "        model.fit(xf_train_params,yf_train_params)\n",
    "        yf_pred = model.predict(xf_val)\n",
    "\n",
    "        return np.sqrt(metrics.mean_squared_error(yf_val, yf_pred))\n",
    "    space = [\n",
    "        (0.001,0.9), #gamma\n",
    "        (1,10000), #C\n",
    "    ]\n",
    "    resultado_gp = gp_minimize(train_model, space, random_state=42, verbose=0, n_calls=30, n_random_starts=10)\n",
    "    \n",
    "    print(\"# Fitting the model\")\n",
    "    regressor = SVR(gamma=resultado_gp.x[0], C=resultado_gp.x[1])\n",
    "    regressor.fit(X_train,y_train)\n",
    "    \n",
    "    print(\"# Making predictions\")\n",
    "    y_pred = regressor.predict(X_test) \n",
    "    y_pred_train = regressor.predict(X_train)\n",
    "    y_pred_train_reshaped = sc_y.inverse_transform(y_pred_train.reshape(-1,1))\n",
    "    y_pred_reshaped = sc_y.inverse_transform(y_pred.reshape(-1,1))\n",
    "    y_train_reshaped = sc_y.inverse_transform(y_train.reshape(-1,1))\n",
    "    \n",
    "    print(\"# Calculating metrics\")\n",
    "    scores = calculate_metrics(y_train_reshaped, y_test, y_pred_reshaped, y_pred_train_reshaped, scores)\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    count += 1\n",
    "print(\"=============== SUMMARY SVR SC ===============\")\n",
    "print(\"# Average Metrics\")\n",
    "print(scores.mean())\n",
    "all_models_scores[\"SVR SC\"] = scores\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"\\nTotal run time:\", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(columns=[\"RATE\"])\n",
    "y_train = train_df[\"RATE\"]\n",
    "\n",
    "with open('selected_cor_features', 'rb') as f:\n",
    "    selected_cor_features = pickle.load(f)\n",
    "    \n",
    "X_train = X_train[selected_cor_features]\n",
    "\n",
    "sc_x = StandardScaler()\n",
    "sc_y = StandardScaler()\n",
    "joblib.dump(sc_x, \"sc_x.save\")\n",
    "joblib.dump(sc_y, \"sc_y.save\")\n",
    "\n",
    "sc_x.fit(X_train)\n",
    "sc_y.fit(y_train)\n",
    "X_train = pd.DataFrame(sc_x.transform(X_train), index=X_train.index, columns=X_train.columns)\n",
    "X_test = pd.DataFrame(sc_x.transform(X_test), index=X_test.index, columns=X_test.columns)\n",
    "y_train = pd.DataFrame(sc_y.transform(y_train), index=y_train.index, columns=y_train.columns)\n",
    "\n",
    "def train_model(params):\n",
    "    gamma = params[0]\n",
    "    C = params[1]\n",
    "\n",
    "    xf_train_params,xf_val,yf_train_params,yf_val = train_test_split(X_train,y_train,test_size=0.33,random_state=42)\n",
    "\n",
    "    model = SVR(gamma=gamma, C=C)\n",
    "\n",
    "    model.fit(xf_train_params,yf_train_params)\n",
    "    yf_pred = model.predict(xf_val)\n",
    "\n",
    "    return np.sqrt(metrics.mean_squared_error(yf_val, yf_pred))\n",
    "space = [\n",
    "    (0.001,0.9), #gamma\n",
    "    (1,10000), #C\n",
    "]\n",
    "resultado_gp = gp_minimize(train_model, space, random_state=42, verbose=0, n_calls=30, n_random_starts=10)\n",
    "\n",
    "regressor = SVR(gamma=resultado_gp.x[0], C=resultado_gp.x[1])\n",
    "regressor.fit(X_train,y_train)\n",
    "\n",
    "filename = root + 'Dashboard/Models/sav/svr_sc_regression.sav'\n",
    "pickle.dump(regressor, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting a summary of all model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame({\"Model\": [], 'rmse_train': [], 'rmse_test':[], \"rmse_baseline_train\": [],\n",
    "                          \"rmse_baseline_test\": [], \"up_down_train\": [], \"up_down_test\": []})\n",
    "\n",
    "for model,scores in all_models_scores.items():\n",
    "    df_result = df_result.append({\"Model\": model,\n",
    "                                 \"rmse_train\": scores[\"rmse_train\"].mean(),\n",
    "                                 \"rmse_test\": scores[\"rmse_test\"].mean(),\n",
    "                                 \"rmse_baseline_train\": scores[\"rmse_baseline_train\"].mean(),\n",
    "                                 \"rmse_baseline_test\": scores[\"rmse_baseline_test\"].mean(),\n",
    "                                 \"up_down_train\": scores[\"up_down_train\"].mean(),\n",
    "                                 \"up_down_test\": scores[\"up_down_test\"].mean()},ignore_index=True)\n",
    "df_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "273.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
